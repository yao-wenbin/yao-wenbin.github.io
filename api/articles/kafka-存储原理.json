{"title":"kafka-存储原理","uid":"dd39451fcd6a79af30692832dae32cef","slug":"kafka-存储原理","date":"2023-08-14T14:00:17.000Z","updated":"2023-08-14T14:02:34.072Z","comments":true,"path":"api/articles/kafka-存储原理.json","cover":null,"content":"<p>本章节将讲解Kafka的底层存储机制，如何实现分区副本的分配、索引机制、如何管理文件以及重要的Kafka压缩机制。</p>\n<h1 id=\"持久化\"><a href=\"#持久化\" class=\"headerlink\" title=\"持久化\"></a>持久化</h1><h2 id=\"文件系统\"><a href=\"#文件系统\" class=\"headerlink\" title=\"文件系统\"></a>文件系统</h2><p>Kafka重度的依赖于文件系统来存储和缓存消息，即使磁盘通常被认为性能十分缓慢。<br>但实际上，磁盘的读写性能取决于其使用的场景。一个设计良好的磁盘结构能够和网络传输一样快。</p>\n<p>磁盘的顺序写入性能在过去的十年里面已经得到了大幅度的提升，得利于现代OS提供的预读（read-ahead）和后写（write-behind）技术。可以大的多倍的数量预读数据，并且将较小的逻辑写入分组为较大的物理写入。 使得顺序的磁盘访问在某些情况下可能比随机内存访问更快。</p>\n<p><a href=\"https://queue.acm.org/detail.cfm?id=1563874\">queue.acm.org&#x2F;detail.cfm?id&#x3D;1563874</a><br><a href=\"https://deliveryimages.acm.org/10.1145/1570000/1563874/jacobs3.jpg\">jacobs3.jpg (585×322) (acm.org)</a></p>\n<p>为了弥补磁盘和内存的性能差异，现代OS中会尽可能地、激进地将内存用于磁盘的缓存。比如说将32GB上产生高达28GB-30GB的缓存，使得写入和读取的都能够直接基于内存，以提高性能。但任何使用过基于JVM的语言使用者都知道两件事</p>\n<ol>\n<li>Java对于内存对象的开销非常高，通常是数据存储的两倍大小（甚至更多）</li>\n<li>随着堆内数据的增加，Java垃圾收集器变得越来越繁琐和缓慢。<br>基于此，对比与使用JVM的堆内存， kafka 更倾向于使用Filesystem文件系统和Linux中的PageCache。</li>\n</ol>\n<p>Kafka提出了一个简单的设计：与其在内存中维护尽可能多的数据，并且在内存空间快要耗尽的时候将其写回文件系统，不如将其翻转。所有的数据立即写入到文件上的持久日志，而不必写回磁盘。 而在Kafka中这样做仅仅意味着它只需要将数据写入Linux内核中的PageCache中。</p>\n<h2 id=\"数据结构\"><a href=\"#数据结构\" class=\"headerlink\" title=\"数据结构\"></a>数据结构</h2><p>持久化的磁盘系统通常倾向于使用BTree或者是其变体的数据结构来存储数据，使得随机访问数据的性能能够达到O(LogN) 。  </p>\n<p>但消息队列不同，其数据都是顺序读和顺序写的，Kafka仅仅只需要将数据追加到文件中就能够实现O(1)的读&#x2F;写时间复杂度。 </p>\n<h2 id=\"分区分配策略\"><a href=\"#分区分配策略\" class=\"headerlink\" title=\"分区分配策略\"></a>分区分配策略</h2><p>为了尽可能的保证高可用和数据容灾的特性，Kafka的分区分配策略会保证三个机制：</p>\n<ol>\n<li>如果Broker设置了机架编号，那么，Partition尽可能的分配到不同的机架上</li>\n<li>Partition分区Leader会尽可能的分布在不同的Broker上</li>\n<li>Partition Replica副本会尽可能的分布在不同的Broker上</li>\n</ol>\n<p>假设我们有两个机架，4个Broker，4个分区，3个副本，那么Kafka能够帮助我们保证实现如下的均衡分布：<br>![Pasted image 20230810114343.png](Pasted image 20230810114343.png)</p>\n<p>一旦Kafka选定了分区所处的Broker，随后还要决定分区要存储在Broker上的某个数据目录中，因为Kafka支持多数据目录，使得Kafka Broker在磁盘空间不足时，允许增加磁盘来继续存储Kafka的数据。</p>\n<p>而Kafka的数据目录的选择很简单，选择具有最少分区数量的数据目录。 这就意味着当有一个新的文件夹增加时，新的分区总是会分配到该文件目录中，因为其是含有最少分区数量的文件夹。</p>\n<h2 id=\"文件管理\"><a href=\"#文件管理\" class=\"headerlink\" title=\"文件管理\"></a>文件管理</h2><p>保留时间是一个重要的概念。消息不会永久的保存在Kafka中，因为消息队列的消息特点是即时，在生产者推送消息至Broker后，Broker立即推送给订阅了消息对应主题的Consumer。 </p>\n<p>Kafka会根据配置文件中的<code>log.retention.ms/bytes</code>的配置决定在何时删除消息，而不是等待所有的消费者都消费完成之后再删除。</p>\n<p>但是删除消息也是一个技术活，消息都存放在文件中，要删除一条消息或者是一个时间戳以前的消息，每次都从文件中查询到对应的消息再删除的话，效率实在太低了。 所以Kafka的删除策略是基于文件的。</p>\n<p>Kafka的消息会存储在<code>log.dir</code>所配置的数据目录的对应主题和分区目录下。<br>![Pasted image 20230810134114.png](Pasted image 20230810134114.png)<br>一个分区下的数据会被分割为多个小文件，每个文件被称之为一个消息段或者是日志段（Log Segments）。每个文件的大小由<code>log.segement.bytes</code>控制，每当文件到达上限时将会关闭对当前文件的写入创建一个新的文件。 每个文件固定20位的长度，表示当前文件所存放的第一条消息的偏移量所决定的。</p>\n<p>有了这样一个基于LogSegement日志段的文件存储方式，Kafka的日志清除策略就简单多了，只要对比每个日志段的时间戳，然后将过期的日志文件删除即可。使得Kafka的删除更加的高效，也能够保证磁盘的利用率不会因为一些过期的消息所占用。</p>\n<p>每个分区中正在被写入的日志段是被视为活跃的，其不会收到<code>log.retention</code>的影响而删除，也就是说，如果你配置了log.retention.ms的时间为一天，但是log.segement.ms为七天。那么日志文件不会在一天之后删除，因为其依然处于活跃的状态。而是在第七天达到log.segement.ms的上限后，关闭该日志文件，而创建新的文件时，该文件才会被删除。</p>\n<h2 id=\"消息格式\"><a href=\"#消息格式\" class=\"headerlink\" title=\"消息格式\"></a>消息格式</h2><p>磁盘上的存储文件和网络中的数据传输都采用一致的消息格式。每一个消息都包含一个Key、Value、Offset、Size、Checksum（校验消息是否完整）、Magic Byte（消息消息格式）、Compression Codedc（压缩算法）、Timestamp（生产者发送消息的时间）</p>\n<p>同时，如果生产者想要发送一批压缩的消息，那么一批压缩的消息会包装为一个Wrapper的Value。 Wrapper也是一个消息的格式，包含着前面所说的消息的所有格式，一批压缩的消息会被作为Value存入这个Wrapper中，看起来像这样：<br>![Pasted image 20230810140021.png](Pasted image 20230810140021.png)</p>\n<h1 id=\"日志压缩-Log-Compaction\"><a href=\"#日志压缩-Log-Compaction\" class=\"headerlink\" title=\"日志压缩 Log Compaction\"></a>日志压缩 Log Compaction</h1><p>除了传统的直接删除的策略，Kafka还支持一种称之为Compact压缩的清除策略。这和我们常说的压缩算法不同，Kafka的压缩将保留主题下每一个Key的最新值。 当你的应用需要存储用户的地址时，保留最新的地址总是比保留七天前的记录要更有意义。</p>\n<p>数据库订阅是日志压缩的一个有用的实际场景。当你的其他应用，比如说搜索引擎，Hadoop，缓存等服务需要订阅来自数据库的记录时，使用日志压缩能够保证数据库的每条记录的最新值被保存下来。</p>\n<p>同时也适用于当应用程序出现故障时，恢复到先前的状态。</p>\n<p>当<code>log.cleanup.polocy</code>参数被配置为<code>compact</code>时，Kafka的清除策略从清除转变为就开始工作了，其会将每个日志段区分为。</p>\n<p>既然每个Key都会被保留一个最新值，那么如何删除无用的Key？ Kafka约定了当Key对应的Value被设置为Null时，Kafka会将其视为是一个墓碑，会在随后清理空间的时候删除。</p>\n<p>日志压缩式通过后台线程来复制Log Segment日志段来实现的，不会阻塞正常日志的读取。同时还支持配置不可超过的I&#x2F;O线程的数量，以防止影响到生产者和消费者线程。</p>\n<p>日志压缩的工作看起来像这样：<br>![Pasted image 20230810221409.png](Pasted image 20230810221409.png)</p>\n<p>日志压缩能够保证以下几点特性使得Kafka正常工作：</p>\n<ol>\n<li>主题的min.compaction.lag.ms和max.compaction.lag.ms能够用于配置当前主题下消息被压缩前的最小时间和最大时间。也就意味着只有当消息写入超过了min.compaction.lag.ms时间之后，Kafka将会将其压缩。</li>\n<li>消息的顺序总是不变的，不会因为压缩而导致顺序混乱。</li>\n<li>消息的偏移量总是不变的，他是消息处于某个位置的永久标识符</li>\n<li>当消费者从消息的头部开始读取时，可能会读取到由<code>delete.retention.ms</code>控制的当前主题的日志清除时间的已经被删除的消息。</li>\n</ol>\n<h2 id><a href=\"#\" class=\"headerlink\" title></a></h2><h1 id=\"Quoata限流\"><a href=\"#Quoata限流\" class=\"headerlink\" title=\"Quoata限流\"></a>Quoata限流</h1><h2 id=\"什么是Quota？\"><a href=\"#什么是Quota？\" class=\"headerlink\" title=\"什么是Quota？\"></a>什么是Quota？</h2><p>Quota叫做配额在英文中是指一个固定的、有限的、被允许的数量。 在RocketMQ和Kafka中意味着限流。</p>\n<p>限流能够保证一些行为异常的客户端的请求得以被限制，防止大量的流量占据了服务器的资源以影响到其他行为正常的客户端。</p>\n<p>Kafka的中的限流主要从两个维度上进行度量的：</p>\n<ol>\n<li>网络带宽，也就是通过X bytes &#x2F; s来限制每个客户端的流量</li>\n<li>请求率限流，请求率被定义为一个客户端的请求能够占用Broker端上的I&#x2F;O线程和网络线程的时间百分比。n % 的配额表示一个线程的上的百分比，而</li>\n</ol>\n<h2 id=\"限流是基于什么维度的？\"><a href=\"#限流是基于什么维度的？\" class=\"headerlink\" title=\"限流是基于什么维度的？\"></a>限流是基于什么维度的？</h2><p>(user, client-id)是kafka中限流的基本维度，user是kafka集群中一组授权的client。而client-id是一组逻辑上相同意义的client，通常这意味着一组相同的应用。</p>\n<p>kafka对于配额的控制是按照细粒度到粗粒度的优先顺序进行加载的：</p>\n<ol>\n<li>&#x2F;config&#x2F;users&#x2F;&lt;user&gt;&#x2F;clients&#x2F;&lt;client-id&gt;</li>\n<li>&#x2F;config&#x2F;users&#x2F;&lt;user&gt;&#x2F;clients&#x2F;&lt;default&gt;</li>\n<li>&#x2F;config&#x2F;users&#x2F;&lt;user&gt;</li>\n<li>&#x2F;config&#x2F;users&#x2F;&lt;default&gt;&#x2F;clients&#x2F;&lt;client-id&gt;</li>\n<li>&#x2F;config&#x2F;users&#x2F;&lt;default&gt;&#x2F;clients&#x2F;&lt;default&gt;</li>\n<li>&#x2F;config&#x2F;users&#x2F;&lt;default&gt;</li>\n<li>&#x2F;config&#x2F;clients&#x2F;&lt;client-id&gt;</li>\n<li>&#x2F;config&#x2F;clients&#x2F;&lt;default&gt;</li>\n</ol>\n<h2 id=\"限流是单节点还是集群的？\"><a href=\"#限流是单节点还是集群的？\" class=\"headerlink\" title=\"限流是单节点还是集群的？\"></a>限流是单节点还是集群的？</h2><p>kafka采取了单个broker节点单独限流的方案，而不是基于整个集群进行统一的限流，因为想要实现分布式集群下的统一配额必然要消耗大量的资源，得不偿失。<br>所以基于单独的配额是一个更具性价比，同时在功能的实现上偏差却不太大的优秀方案。</p>\n<h2 id=\"限流的具体实现是如何的？\"><a href=\"#限流的具体实现是如何的？\" class=\"headerlink\" title=\"限流的具体实现是如何的？\"></a>限流的具体实现是如何的？</h2><p>两种限流的方式：基于数据传输大小 和 基于线程数量的配额都是在一个30个1s的较小测量窗口中进行的。 使得kafka能够及时的检测和纠正限流的情况。 </p>\n<p>如果将测量窗口设置的太大，会导致大量的流量突发，然后产生较大的delay，这种情况下用户的体验就很差了。</p>\n<h2 id=\"限流触发后，broker和client还会正常工作吗？\"><a href=\"#限流触发后，broker和client还会正常工作吗？\" class=\"headerlink\" title=\"限流触发后，broker和client还会正常工作吗？\"></a>限流触发后，broker和client还会正常工作吗？</h2><p>当一个客户端触发了限流之后，kafka的broker会为其计算一个delay的延迟并且立即响应该延迟。</p>\n<p>随后，在延迟时间为到达之前，broker对于该客户端的每次fetch请求都不会响应任何数据。</p>\n<p>而当kafka的客户端在将接收到broker的delay延迟响应之后，也不会再向broker端发送任何请求。</p>\n<p>这种双向限流的方式使得kafka能够在一些旧版本的broker或者是client中也能够轻松的实现限流。</p>\n<h1 id=\"日志副本Replica\"><a href=\"#日志副本Replica\" class=\"headerlink\" title=\"日志副本Replica\"></a>日志副本Replica</h1><p>日志副本是Kafka架构中的核心， 也是kafka能够保证高可用和持久化的根本。 使得Broker节点集群在发生故障的时候，仍然保持集群的高可用，也是的Kafka Broker节点的数据发生损坏时，依然能够恢复。</p>\n<h2 id=\"如何设定日志副本\"><a href=\"#如何设定日志副本\" class=\"headerlink\" title=\"如何设定日志副本\"></a>如何设定日志副本</h2><p>kafka中的日志副本是基于主题来设置，基于主题的分区作为副本的基本单元。</p>\n<p>默认情况下每个分区都只会有一个副本，在创建主题时，你可以通过–replication-factor &lt;N&gt;来指定主题的副本数量</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">bin/kafka-topics.sh <span class=\"token parameter variable\">--create</span> <span class=\"token parameter variable\">--zookeeper</span> localhost:2181 --replication-factor <span class=\"token number\">1</span> <span class=\"token parameter variable\">--partitions</span> <span class=\"token number\">3</span> <span class=\"token parameter variable\">--topic</span> my-topic<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n\n\n<p>设定多个副本之后，kafka会为每一个分区都产生多个副本，并且均衡的分布在kafka集群中。每个副本中的日志具有完全相同的消息和偏移量。</p>\n<h2 id=\"多副本之间的如何工作？\"><a href=\"#多副本之间的如何工作？\" class=\"headerlink\" title=\"多副本之间的如何工作？\"></a>多副本之间的如何工作？</h2><p>每个分区的Replica都会有一个Leader Replica，消息的生产和消费都有Leader Replica所在的节点来处理。</p>\n<p>而分区中的其他Replica，都为Follower Replica，其并不会处理来自客户端的请求，其日常任务就是不断的向Leader Replica中发送同步消息的请求。 但是一旦Leader Replica的节点出现了故障，那么Follower Replica将会选举出一个新的Leader Replica，并且接管原本Leader Replica的任务。</p>\n<h2 id=\"Follower-Replica-是如何工作的？\"><a href=\"#Follower-Replica-是如何工作的？\" class=\"headerlink\" title=\"Follower Replica 是如何工作的？\"></a>Follower Replica 是如何工作的？</h2><p>Follower 会不断的向 Leader 节点发送 Fetch 请求，请求就如同消费客户端请求类型一样，会顺序的获取Leader节点上的数据，并且包含了Follower下一个想要获取的消息的偏移量。</p>\n<p>Follower 的每一个 Fetch 请求都是同步进行的，先请求消息1，再请求消息2，等待消息2相应成功之后才会请求消息3。<br>Leader 节点对于来自 Follower 的 Fetch 请求时，还会告知Follower 其现在落后的进度。</p>\n<h2 id=\"什么是ISR？\"><a href=\"#什么是ISR？\" class=\"headerlink\" title=\"什么是ISR？\"></a>什么是ISR？</h2><p>每一个 Leader Replica 都会维护一个ISR（In-Sync Replica）集合，其包含着该分区的当前可用的副本集合。 默认情况下ISR中存放着每一个 Follower Replica，但是当一个 Follower 被认为是挂掉的时候，就会从ISR中剔除。</p>\n<h2 id=\"剔除ISR副本是按照什么规则来的？\"><a href=\"#剔除ISR副本是按照什么规则来的？\" class=\"headerlink\" title=\"剔除ISR副本是按照什么规则来的？\"></a>剔除ISR副本是按照什么规则来的？</h2><p>kafka中 Leader Replica 剔除ISR中的节点的规则有两个：</p>\n<ol>\n<li>当 Leader 节点超过 10s 未收到 一个Follower 的Fetch请求时。（kraft模式通过broker.session.timeout.ms配置，zookeeper模式通过zookeeper.session.timeout.ms设置）</li>\n<li>当 Follower 节点的同步进度落后于 Leader  节点超过10s时（通过replica.lag.time.max.ms参数所配置）。</li>\n</ol>\n<h2 id=\"什么是Preferred-Leader？\"><a href=\"#什么是Preferred-Leader？\" class=\"headerlink\" title=\"什么是Preferred Leader？\"></a>什么是Preferred Leader？</h2><p>kafka中将负载均衡做到了极致，每一个Partition都会有有一个Preferred Leader Replica节点，随着Partition的创建而设定，来自多个分区的 Preferred Leader 其会均匀的分布在Broker节点中。 </p>\n<p>默认情况下，kafka 节点还会检查每个分区中 Current Leader 是否是Preferred Leader，如果不是的话，会尝试将 Leader 转移到 Preferred Leader节点中。（auto.leader.reblance.enable &#x3D; true）</p>\n<h2 id=\"副本对于生产者的影响\"><a href=\"#副本对于生产者的影响\" class=\"headerlink\" title=\"副本对于生产者的影响\"></a>副本对于生产者的影响</h2><p>通过生产者的配置，kafka的生产者可以选择当消息被发送至kafka broker节点中的0个或满足quorum或所有节点时才响应发送成功。 </p>\n<p>这意味着你需要对消息基于延迟和持久性的进行权衡。</p>\n<h2 id=\"副本对消费者的影响\"><a href=\"#副本对消费者的影响\" class=\"headerlink\" title=\"副本对消费者的影响\"></a>副本对消费者的影响</h2><p>kafka中只有消息被存入其对应分区下所有的ISR中才会被视为提交。 只有提交后的消息才能够被消费者，这也就意味着每当消费者接收到一条消息之后，能够保证这个消息是正确的被投递的，而不会产生回滚之类的可能。</p>\n<h2 id=\"为什么kafka要选择ISR，而不是Raft协议或者是ZK？\"><a href=\"#为什么kafka要选择ISR，而不是Raft协议或者是ZK？\" class=\"headerlink\" title=\"为什么kafka要选择ISR，而不是Raft协议或者是ZK？\"></a>为什么kafka要选择ISR，而不是Raft协议或者是ZK？</h2><p>目前许多分布式系统都会采用Raft或者是ZK的ZAB算法来实现副本同步，其核心的策略就是当你定义了2n</p>\n<p>Raft协议中在提交日志或者是Leader选举中都是用了“多数票”的方法。 假设有 2n + 1 个副本，仅当 有 n + 1个副本同步了Leader节点的数据时，Leader节点的日志才会被视为时提交的。 这样我们能够保证在所有 n + 1的副本中，至少有一个副本包含所有已提交的消息。 该副本的日志将是最完整的，能够被选举为新的Leader。</p>\n<p>Raft协议基于quorum的多数投票方法的一个优点就是总是能够根据响应最快的几个节点来响应同步请求或者是选举请求。 一些较慢的服务器不会拖延整个集群的后腿。</p>\n<h2 id=\"Raft协议有什么缺陷？\"><a href=\"#Raft协议有什么缺陷？\" class=\"headerlink\" title=\"Raft协议有什么缺陷？\"></a>Raft协议有什么缺陷？</h2><p>这就意味着每部署 2 n + 1 个副本，Raft协议仅能够容忍n &#x2F; 2个故障。 3个节点只能够允许1节点在一个时刻发生故障，而5个节点只能够允许2个节点。 这样的部署成本就比较大，想要多增加n个节点的故障能力就需要增加2n个副本数量。这就是为什么quorum算法更常用于共享集群配置比如ZK，而不是重要数据存储的原因。 因为quorum实现的重要数据存储更加的昂贵。</p>\n<h2 id=\"ISR是如何解决Raft缺陷的？\"><a href=\"#ISR是如何解决Raft缺陷的？\" class=\"headerlink\" title=\"ISR是如何解决Raft缺陷的？\"></a>ISR是如何解决Raft缺陷的？</h2><p>kafka的实现与quorum投票的方式稍有不同，kafka内部动态地维护一组同步副本ISR。<br>每个ISR中的节点都够保证跟上leader的步伐。这也就意味着，当故障发生时，kafka的ISR中的存活节点能够被直接选举为一个可用的Leader，而不必担心候选者的日志是否与达到最新的状态，与故障Leader一致。</p>\n<p>这种模型下，n + 1的副本能够保证n的容忍故障，而不会有日志丢失的风险。</p>\n<p>当然，这种更优的部署是在性能的权衡下保证的。在日志的提交中 quorum 仅需要 n &#x2F; 2个节点响应同步请求即可，而 ISR 需要集合中的所有节点都响应</p>\n<h2 id=\"什么是最小同步副本？\"><a href=\"#什么是最小同步副本？\" class=\"headerlink\" title=\"什么是最小同步副本？\"></a>什么是最小同步副本？</h2><h1 id=\"Controller-集群控制器\"><a href=\"#Controller-集群控制器\" class=\"headerlink\" title=\"Controller 集群控制器\"></a>Controller 集群控制器</h1><h2 id=\"什么是控制器？\"><a href=\"#什么是控制器？\" class=\"headerlink\" title=\"什么是控制器？\"></a>什么是控制器？</h2><p>kakfa集群中，第一个启动的节点会在Zookeeper中注册一个ephemeral临时节点，名为&#x2F;controller。其他节点在启动时也会执行同样的操作，但是当发现&#x2F;controller已存在时，触发一个异常，使其意识到当前集群中controller控制器已经存在了。</p>\n<p>controller会通过Zookeeper来注册一个Zookeeper Watch观察者，用于监听集群中每一个节点中的状态。  同时为了防止“脑裂”，控制器会使用一个 epoch （任期或者说纪元）来标明当前controller。</p>\n<h2 id=\"当一个节点下线时会发生什么？\"><a href=\"#当一个节点下线时会发生什么？\" class=\"headerlink\" title=\"当一个节点下线时会发生什么？\"></a>当一个节点下线时会发生什么？</h2><p>当一个节点发生下线时， controller会意识到该节点上的Leader Replica，需要一个新的leader了。其会遍历该分区的ISR的下一个节点，将其作为新的Leader，并且通知 ISR 中的其他节点，当前分区的Leader已经易主了， 该通知请求中包含了新的Leader 和 新的Follower 们。</p>\n<p>新的 Leader 在接收到请求之后，就意识到自身变为了新的 Leader 便开始接受来自 Consumer 和 Producer 的请求了。</p>\n<h2 id=\"当节点重新上线又会发生什么？\"><a href=\"#当节点重新上线又会发生什么？\" class=\"headerlink\" title=\"当节点重新上线又会发生什么？\"></a>当节点重新上线又会发生什么？</h2><p>当一个节点重新上线后，Controller 控制器会通过配置文件中的 brokerid 来检验当前节点是否存在副本，如果存在副本的话，会通知副本分区中的所有节点，有曾经下线的节点重新上线了，随后该节点会开始向 Leader 发送日志同步请求。</p>\n<h1 id=\"消息幂等性\"><a href=\"#消息幂等性\" class=\"headerlink\" title=\"消息幂等性\"></a>消息幂等性</h1>","text":"本章节将讲解Kafka的底层存储机制，如何实现分区副本的分配、索引机制、如何管理文件以及重要的Kafka压缩机制。 持久化文件系统Kafka重度的依赖于文件系统来存储和缓存消息，即使磁盘通常被认为性能十分缓慢。但实际上，磁盘的读写性能取决于其使用的场景。一个设计良好的磁盘结构能够...","link":"","photos":[],"count_time":{"symbolsCount":"8.2k","symbolsTime":"7 mins."},"categories":[],"tags":[{"name":"MQ","slug":"MQ","count":5,"path":"api/tags/MQ.json"},{"name":"Raft","slug":"Raft","count":1,"path":"api/tags/Raft.json"},{"name":"Rate Limiting","slug":"Rate-Limiting","count":1,"path":"api/tags/Rate-Limiting.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E6%8C%81%E4%B9%85%E5%8C%96\"><span class=\"toc-text\">持久化</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F\"><span class=\"toc-text\">文件系统</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84\"><span class=\"toc-text\">数据结构</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5\"><span class=\"toc-text\">分区分配策略</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86\"><span class=\"toc-text\">文件管理</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%B6%88%E6%81%AF%E6%A0%BC%E5%BC%8F\"><span class=\"toc-text\">消息格式</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E6%97%A5%E5%BF%97%E5%8E%8B%E7%BC%A9-Log-Compaction\"><span class=\"toc-text\">日志压缩 Log Compaction</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\"><span class=\"toc-text\"></span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#Quoata%E9%99%90%E6%B5%81\"><span class=\"toc-text\">Quoata限流</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%BB%80%E4%B9%88%E6%98%AFQuota%EF%BC%9F\"><span class=\"toc-text\">什么是Quota？</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E9%99%90%E6%B5%81%E6%98%AF%E5%9F%BA%E4%BA%8E%E4%BB%80%E4%B9%88%E7%BB%B4%E5%BA%A6%E7%9A%84%EF%BC%9F\"><span class=\"toc-text\">限流是基于什么维度的？</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E9%99%90%E6%B5%81%E6%98%AF%E5%8D%95%E8%8A%82%E7%82%B9%E8%BF%98%E6%98%AF%E9%9B%86%E7%BE%A4%E7%9A%84%EF%BC%9F\"><span class=\"toc-text\">限流是单节点还是集群的？</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E9%99%90%E6%B5%81%E7%9A%84%E5%85%B7%E4%BD%93%E5%AE%9E%E7%8E%B0%E6%98%AF%E5%A6%82%E4%BD%95%E7%9A%84%EF%BC%9F\"><span class=\"toc-text\">限流的具体实现是如何的？</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E9%99%90%E6%B5%81%E8%A7%A6%E5%8F%91%E5%90%8E%EF%BC%8Cbroker%E5%92%8Cclient%E8%BF%98%E4%BC%9A%E6%AD%A3%E5%B8%B8%E5%B7%A5%E4%BD%9C%E5%90%97%EF%BC%9F\"><span class=\"toc-text\">限流触发后，broker和client还会正常工作吗？</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E6%97%A5%E5%BF%97%E5%89%AF%E6%9C%ACReplica\"><span class=\"toc-text\">日志副本Replica</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%A6%82%E4%BD%95%E8%AE%BE%E5%AE%9A%E6%97%A5%E5%BF%97%E5%89%AF%E6%9C%AC\"><span class=\"toc-text\">如何设定日志副本</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%A4%9A%E5%89%AF%E6%9C%AC%E4%B9%8B%E9%97%B4%E7%9A%84%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C%EF%BC%9F\"><span class=\"toc-text\">多副本之间的如何工作？</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#Follower-Replica-%E6%98%AF%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C%E7%9A%84%EF%BC%9F\"><span class=\"toc-text\">Follower Replica 是如何工作的？</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%BB%80%E4%B9%88%E6%98%AFISR%EF%BC%9F\"><span class=\"toc-text\">什么是ISR？</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%89%94%E9%99%A4ISR%E5%89%AF%E6%9C%AC%E6%98%AF%E6%8C%89%E7%85%A7%E4%BB%80%E4%B9%88%E8%A7%84%E5%88%99%E6%9D%A5%E7%9A%84%EF%BC%9F\"><span class=\"toc-text\">剔除ISR副本是按照什么规则来的？</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%BB%80%E4%B9%88%E6%98%AFPreferred-Leader%EF%BC%9F\"><span class=\"toc-text\">什么是Preferred Leader？</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%89%AF%E6%9C%AC%E5%AF%B9%E4%BA%8E%E7%94%9F%E4%BA%A7%E8%80%85%E7%9A%84%E5%BD%B1%E5%93%8D\"><span class=\"toc-text\">副本对于生产者的影响</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%89%AF%E6%9C%AC%E5%AF%B9%E6%B6%88%E8%B4%B9%E8%80%85%E7%9A%84%E5%BD%B1%E5%93%8D\"><span class=\"toc-text\">副本对消费者的影响</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%B8%BA%E4%BB%80%E4%B9%88kafka%E8%A6%81%E9%80%89%E6%8B%A9ISR%EF%BC%8C%E8%80%8C%E4%B8%8D%E6%98%AFRaft%E5%8D%8F%E8%AE%AE%E6%88%96%E8%80%85%E6%98%AFZK%EF%BC%9F\"><span class=\"toc-text\">为什么kafka要选择ISR，而不是Raft协议或者是ZK？</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#Raft%E5%8D%8F%E8%AE%AE%E6%9C%89%E4%BB%80%E4%B9%88%E7%BC%BA%E9%99%B7%EF%BC%9F\"><span class=\"toc-text\">Raft协议有什么缺陷？</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#ISR%E6%98%AF%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3Raft%E7%BC%BA%E9%99%B7%E7%9A%84%EF%BC%9F\"><span class=\"toc-text\">ISR是如何解决Raft缺陷的？</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%BB%80%E4%B9%88%E6%98%AF%E6%9C%80%E5%B0%8F%E5%90%8C%E6%AD%A5%E5%89%AF%E6%9C%AC%EF%BC%9F\"><span class=\"toc-text\">什么是最小同步副本？</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#Controller-%E9%9B%86%E7%BE%A4%E6%8E%A7%E5%88%B6%E5%99%A8\"><span class=\"toc-text\">Controller 集群控制器</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%BB%80%E4%B9%88%E6%98%AF%E6%8E%A7%E5%88%B6%E5%99%A8%EF%BC%9F\"><span class=\"toc-text\">什么是控制器？</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%BD%93%E4%B8%80%E4%B8%AA%E8%8A%82%E7%82%B9%E4%B8%8B%E7%BA%BF%E6%97%B6%E4%BC%9A%E5%8F%91%E7%94%9F%E4%BB%80%E4%B9%88%EF%BC%9F\"><span class=\"toc-text\">当一个节点下线时会发生什么？</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%BD%93%E8%8A%82%E7%82%B9%E9%87%8D%E6%96%B0%E4%B8%8A%E7%BA%BF%E5%8F%88%E4%BC%9A%E5%8F%91%E7%94%9F%E4%BB%80%E4%B9%88%EF%BC%9F\"><span class=\"toc-text\">当节点重新上线又会发生什么？</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E6%B6%88%E6%81%AF%E5%B9%82%E7%AD%89%E6%80%A7\"><span class=\"toc-text\">消息幂等性</span></a></li></ol>","author":{"name":"姚文彬","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"深入底层 掌握脉搏","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"你真的了解你的MySQL吗(MySQL基准测试)","uid":"4468f948c4ca4e742d657728958a113e","slug":"你真的了解你的MySQL吗-MySQL基准测试","date":"2022-11-12T13:31:33.000Z","updated":"2022-11-12T13:31:47.878Z","comments":true,"path":"api/articles/你真的了解你的MySQL吗-MySQL基准测试.json","cover":[],"text":"如果你没有真正的对服务器上的MySQL进行基准测试，就无法了解其真实情况到底是如何。 基准测试是数据库工程师必备的技能之一，否则你如何知道自己真的在优化数据库？ 为什么需要基测？基测可以观察系统在不同压力下的行为： 验证基于系统的一些假设是否符合实际情况。 测试当前的运行情况，如...","link":"","photos":[],"count_time":{"symbolsCount":"7k","symbolsTime":"6 mins."},"categories":[],"tags":[{"name":"MySQL","slug":"MySQL","count":5,"path":"api/tags/MySQL.json"}],"author":{"name":"姚文彬","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"深入底层 掌握脉搏","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true},"next_post":{"title":"kafka-请求处理","uid":"d709ff68faafebbf1f49a2d66baac1a6","slug":"kafka-请求处理","date":"2023-08-14T13:59:14.000Z","updated":"2023-08-14T14:02:59.448Z","comments":true,"path":"api/articles/kafka-请求处理.json","cover":null,"text":"kafka中broker与client的交互都是通过TCP协议来实现的，通过固定的请求格式和请求响应。 任何请求都能够按照顺序被响应，使得 kafka 能够向队列一样保证消息的存储数据。 请求头由什么构成？每个请求头都包含四个固定的参数： Request type，请求类型，也叫...","link":"","photos":[],"count_time":{"symbolsCount":"1.4k","symbolsTime":"1 mins."},"categories":[],"tags":[{"name":"MQ","slug":"MQ","count":5,"path":"api/tags/MQ.json"}],"author":{"name":"姚文彬","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"深入底层 掌握脉搏","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}}